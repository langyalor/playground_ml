{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################\n",
    "#       d888888b                         d888888b\n",
    "#    d888    8888b                    d888888   888b\n",
    "#  d88    88  898888b               d8888  888     88b\n",
    "# d8P        88888888b             d88888888888     b8b\n",
    "# 88        8888888888             88888888888       88\n",
    "# 88       88888888888             8888888888        88\n",
    "# 98b     88888888888P             988888888        d8P\n",
    "#  988     888  8888P      _=_      9888898  88    88P\n",
    "#    9888   888888P      q(-_-)p       98888    888P\n",
    "#       9888888P         '_) (_`         9888888P\n",
    "#          88            /__/  \\            88\n",
    "#          88          _(<_   / )_          88\n",
    "#         d88b        (__\\_\\_|_/__)        d88b\n",
    "###\n",
    "###                  佛祖保佑，Bug退去；\n",
    "###                  阿弥陀佛，善哉善哉\n",
    "# ###############################################################\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 图像预处理\n",
    "def preprocess(file_name):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    chs = cv2.split(img)\n",
    "    hue = ((chs[0] > 30) * 1) * chs[0]\n",
    "    res = ((hue < 50) * 1) * hue\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    res = cv2.morphologyEx(res.astype(np.float32), cv2.MORPH_ERODE, kernel)\n",
    "    resize = cv2.resize(res, (196, 196))\n",
    "    resize = resize.reshape((1, 196, 196))\n",
    "    resize = cv2.normalize(resize, resize, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    cv2.imwrite(\"test.jpg\", resize[0])\n",
    "\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750\n",
      "4750\n"
     ]
    }
   ],
   "source": [
    "train_path = '/media/lor/data/data/plant-seedlings-classification/train'\n",
    "train_samples = []\n",
    "train_labels = []\n",
    "label_to_idx = {}\n",
    "for (i, cat) in enumerate(os.listdir(train_path)):\n",
    "    label_to_idx[cat] = i\n",
    "    cat_path = os.path.join(train_path, cat)\n",
    "#     print(cat_path)\n",
    "    for item in os.listdir(cat_path):\n",
    "        train_labels.append(i)\n",
    "        train_samples.append(os.path.join(cat_path, item))\n",
    "print(len(train_labels))\n",
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, targets):\n",
    "        self.samples = samples\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.targets[idx]\n",
    "        sample = preprocess(self.samples[idx])\n",
    "        sample = sample / 255\n",
    "        return (target, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantDS(train_samples, train_labels)\n",
    "indices = list(range(train_ds.__len__()))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[0:4000]\n",
    "valid_indices = indices[4000:4750]\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = torch.utils.data.DataLoader(train_ds, batch_size=16, num_workers=4, sampler=train_sampler)\n",
    "valid_dloader = torch.utils.data.DataLoader(train_ds, batch_size=1, num_workers=4, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlantNet, self).__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "                        nn.Conv2d(1, 6, kernel_size=(3, 3), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(6),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(6, 16, kernel_size=(5, 5), stride=1, padding=2),\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "        )\n",
    "        self.layer_2 = nn.Sequential(\n",
    "                        nn.Conv2d(16, 24, kernel_size=(5, 5), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(24),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "                        nn.Conv2d(24, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=(3, 3), stride=3),\n",
    "        )\n",
    "        \n",
    "        self.layer_3 = nn.Linear(16 * 16 * 32, 910)\n",
    "#         self.layer_4 = nn.Linear(2730, 910)\n",
    "        self.layer_5 = nn.Linear(910, 303)\n",
    "        self.layer_6 = nn.Linear(303, 12)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.layer_3(out)\n",
    "#         out = self.layer_4(F.relu(out))\n",
    "        out = self.layer_5(F.relu(out))\n",
    "        out = self.layer_6(F.relu(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "net = PlantNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "total_step = len(train_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/250], Loss: 1.7785\n",
      "Epoch [1/10], Step [200/250], Loss: 1.2821\n",
      "Epoch [2/10], Step [100/250], Loss: 1.1773\n",
      "Epoch [2/10], Step [200/250], Loss: 1.1284\n",
      "Epoch [3/10], Step [100/250], Loss: 0.5772\n",
      "Epoch [3/10], Step [200/250], Loss: 1.0173\n",
      "Epoch [4/10], Step [100/250], Loss: 0.4671\n",
      "Epoch [4/10], Step [200/250], Loss: 0.5629\n",
      "Epoch [5/10], Step [100/250], Loss: 0.5002\n",
      "Epoch [5/10], Step [200/250], Loss: 0.4988\n",
      "Epoch [6/10], Step [100/250], Loss: 0.3532\n",
      "Epoch [6/10], Step [200/250], Loss: 0.2194\n",
      "Epoch [7/10], Step [100/250], Loss: 0.0781\n",
      "Epoch [7/10], Step [200/250], Loss: 0.1430\n",
      "Epoch [8/10], Step [100/250], Loss: 0.0858\n",
      "Epoch [8/10], Step [200/250], Loss: 0.1683\n",
      "Epoch [9/10], Step [100/250], Loss: 0.0779\n",
      "Epoch [9/10], Step [200/250], Loss: 0.3099\n",
      "Epoch [10/10], Step [100/250], Loss: 0.0440\n",
      "Epoch [10/10], Step [200/250], Loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (target, sample) in enumerate(train_dloader):\n",
    "        pred = net(sample)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "total = 0\n",
    "for (target, sample) in valid_dloader:\n",
    "    pred = net(sample)\n",
    "    total = total + (torch.argmax(pred, 1) == target).sum().item()\n",
    "\n",
    "print(\"Accuracy: {0}%\".format(100 * total / len(valid_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
